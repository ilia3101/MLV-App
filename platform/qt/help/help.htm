<p>Welcome to the MLV-App wiki!</p>
<p>Here we will try to write down a kind of user manual and how we realized the key features of MLV App.</p>
<h1 id="1-definitions">1. Definitions</h1>
<h2 id="session">Session</h2>
<p>A session consists of a set of MLV clips. For each clip one receipt is saved.</p>
<h2 id="receipt">Receipt</h2>
<p>A receipt contains all settings from edit area for one clip.</p>
<h1 id="2-menu">2. Menu</h1>
<h2 id="2-1-file">2.1 File</h2>
<h3 id="new-session">New Session</h3>
<p>Create a new empty session. If you are in a session, this session will be closed.</p>
<h3 id="open-session">Open Session</h3>
<p>Opens an existing session from disk.</p>
<h3 id="save-session">Save Session</h3>
<p>Saves the opened session to disk.</p>
<h3 id="create-mapp-files">Create MAPP Files</h3>
<p>A MAPP file contains video frame index (absolute offsets to all video frames start in MLV). MAPP also includes audio frame index and all needed block header copies. Hence there is no need to open and scan MLV file second time at all. Audio index simplifies audio data access when this data is to be loaded. WAV file is not saved separately. So when MAPP is active and MLV does not contain audio, the second loading is lightning fast.</p>
<h3 id="import-mlv">Import MLV</h3>
<p>This action imports (a) MLV file(s) to the session.</p>
<h3 id="fcpxml-import-assistant">FCPXML Import Assistant</h3>
<p>This opens a dialog, which helps opening all used clips from a FCPXML project file. The assistant trys to find a MLV equivalent to the clips from the FCPXML project.</p>
<p><em>Example: as first step for a project all recorded MLV files were opened and all clips were exported as proxy. As second step, the project was cut in a NLE. As third step, all used clips shall be graded and exported with maximal quality. Here, this assistant helps opening only the used clips to the session.</em></p>
<p><img src=":/help/help/fcpxml.png" alt="bildschirmfoto 2018-08-11 um 16 05 49"></p>
<h3 id="fcpxml-selection-assistant">FCPXML Selection Assistant</h3>
<p>This opens a dialog, which helps selecting all used clips from a FCPXML project file. The assistant trys to find the equivalent clips in the session and selects them. The selection can be inverted.</p>
<p><em>Example: as first step for a project all recorded MLV files were opened, some adjustments were made and all clips were exported as proxy. As second step, the project was cut in a NLE. As third step, all used clips shall be graded and exported with maximal quality. Here, this assistant helps removing the unused clips from the session. So the adjustments from step one don&#39;t get lost.</em></p>
<h3 id="clip-information">Clip Information</h3>
<p>Open a dialog, which shows the metadata from the MLV file.</p>
<h3 id="export-selected-clips">Export Selected Clips</h3>
<p>This action exports the clips, which are selected in the Session List area, using the selected codec from Export Settings.</p>
<h3 id="export-actual-frame">Export Actual Frame</h3>
<p>Export the frame shown in the viewer as PNG, uncompressed or lossless DNG file.</p>
<h3 id="export-settings">Export Settings</h3>
<p>Setup the export settings. They consist of the codec, codec option, debayer (demosaic algorithm), resolution (ffmpeg codecs only), framerate override (ffmpeg only &amp; AVFoundation), Smooth aliasing (ffmpeg only), HDR blending (ffmpeg only), audio, post export script (OSX only).</p>
<p>Audio can only be exported, if framerate override is not activated and if chosen codec supports audio export.</p>
<p>CinemaDNG export only contains RAW Correction parameters and CutIn&amp;CutOut applied. All other parameters from edit area don&#39;t affect the exported file.</p>
<p>MLV export only contains CutIn&amp;CutOut applied. All other parameters from edit area don&#39;t affect the exported file.</p>
<p>Smooth aliasing smooths aliasing artifacts. This works best for clips with a very slight movement.
<em>Note: Smooth aliasing runs when progressbar is at 100% and needs a long time to render.</em></p>
<p>Export setting presets can be saved and loaded. First setup a setting, then click &quot;+&quot; button. Rename a listed preset by doubleclicking. Load a preset by a single click. Delete a selected preset by clicking &quot;-&quot; button.</p>
<h2 id="2-2-edit">2.2 Edit</h2>
<h3 id="copy-receipt">Copy Receipt</h3>
<p>First, this opens a dialog where the user is able to select the settings only, which shall be copied to another/other clip(s) from the session. The selected settings from the selected clip will be copied to clipboard.</p>
<h3 id="paste-receipt">Paste Receipt</h3>
<p>The receipt settings copied to clipboard will be pasted to all selected clips in the session list, or to the opened clip in the case of no selection.</p>
<h3 id="export-receipt">Export Receipt</h3>
<p>This is the same like Copy Receipt, but the receipt is not copied to clipboard - it is saved to a file on disk.</p>
<h3 id="import-receipt">Import Receipt</h3>
<p>This pastes a receipt which was previously saved to disk to all selected clips, or to the opened clip in the case of no selection.</p>
<h3 id="reset-receipt">Reset Receipt</h3>
<p>This resets all parameters from the receipt (in the edit area) to their default. <em>Note: a single parameter can be reset by doubleclicking on the slider handle.</em></p>
<h3 id="use-default-receipt">Use Default Receipt</h3>
<p>Select a receipt and use it for all imported clips.</p>
<h2 id="2-3-playback">2.3 Playback</h2>
<h3 id="enable-audio-output">Enable Audio Output</h3>
<p>This enables/disables the audio output on playback.</p>
<h3 id="remember-playback-position">Remember Playback Position</h3>
<p>This saves the last playback position for each clip loaded in the session. If a clip in the session is selected again, this last playback position is reloaded.</p>
<h3 id="drop-frame-mode">Drop Frame Mode</h3>
<p>There are two different playback modes: non drop frame mode, and drop frame mode. The first one shows all frames from the clip, when playing the clip. On slower computers this will look like slowmotion. In order to preview the clip in realtime (here: synced to real world time and synced to audio (if availlable)), drop frame mode can be used (all frames which can&#39;t be rendered and shown in time will be ignored).</p>
<h3 id="debayer-for-preview">Debayer for Preview</h3>
<p>This changes the demosaicing algorithm used for the viewer. The demosaicing algorithm is one of the most time consuming parts in the processing pipeline, depending on the chosen algorithm. On the other side preview quality also depends the chosen algorithm. The fastest algorithm is &quot;Simple&quot; and the (mostly) best algorithm is &quot;AMaZE&quot;. </p>
<h3 id="better-resizer-for-viewer">Better Resizer for Viewer</h3>
<p>When enabled AVIR resizer is used for the viewer, when stretching is used in transformation groupbox. When disabled an algorithm with lower quality but higher speed is used.</p>
<h1 id="3-demosaicing-algorithms">3. Demosaicing Algorithms</h1>
<p><img src="https://pictshare.net/mzpqdk9o9j.gif" alt="Demosaicing algorithm demonstation"></p>
<h3 id="none">None</h3>
<p>No debayering will run. This just copies monochrome color information from RAW to shown picture. Depending on chosen WhiteBalance, the picture could be colored to one single color.</p>
<h3 id="simple">Simple</h3>
<p>This is a very fast but stupid demosaicing algorithm. It interprets a 2x2 pixel array (RGGB) to a color. This looks not very fine, consists of copying actions mostly. No interpolation is done at all.</p>
<h3 id="bilinear">Bilinear</h3>
<p>Is a very fast algorithm, and interpolates colors between the pixels. Looks better than &quot;Simple&quot;.</p>
<h3 id="lmmse">LMMSE</h3>
<p>Zhang-Wu LMMSE Image Demosaicking - Color demosaicking via directional linear minimum mean square-error estimation.</p>
<h3 id="igv">IGV</h3>
<p>Bayer CFA Demosaicing using Integrated Gaussian Vector on Color Differences. Looks best on high ISO clips.</p>
<h3 id="amaze">AMaZE</h3>
<p>Aliasing Minimization and Zipper Elimination. Looks best mostly.</p>
<h3 id="ahd">AHD</h3>
<p>Adaptive Homogeneity-Directed interpolation is based on the work of Keigo Hirakawa, Thomas Parks, and Paul Lee.</p>
<h1 id="4-edit-area">4. Edit Area</h1>
<h2 id="4-1-raw-correction">4.1 RAW Correction</h2>
<h3 id="enable-raw-correction">Enable RAW Correction</h3>
<p>Switch the whole RAW Correction block on/off.</p>
<h3 id="darkframe-subtraction">Darkframe Subtraction</h3>
<p>Use this to remove static noise from the clip.</p>
<ul>
<li>Record with identical settings and identical equipment a clip with lens cap mounted. Some seconds are enough.</li>
<li>Import MLV into MLVApp.</li>
<li>Export this file as MLV, Averaged Frame. Now you have your darkframe.</li>
<li>Import your clip.</li>
<li>Go to RAW Corrections, press darkframe folder icon and select your darkframe. Static noise will be removed now.<h3 id="fix-focus-dots">Fix Focus Dots</h3>
Cameras like EOS 100D, 700D,... have wrong colored focus dots in the image. These dots can be removed using this option. </li>
</ul>
<p><img src=":/help/help/focusdots.png" alt="bildschirmfoto 2018-09-23 um 13 38 08"></p>
<p>Via drag and drop to the MLVApp window, new focus pixel maps can be installed. Additionally installed focus pixel maps are located next to the MLVApp executable. Get current focus pixel maps for your camera e.g. <a href="https://github.com/ilia3101/MLV-App/tree/master/pixel_maps/">from here</a>. The first number of focus pixel maps is the camera id:</p>
<ul>
<li>Canon EOS 650D, Canon EOS Rebel T4i, Canon EOS Kiss X6i: <em>80000301</em></li>
<li>Canon EOS 700D, Canon EOS Rebel T5i, Canon EOS Kiss X7i: <em>80000326</em></li>
<li>Canon EOS M: <em>80000331</em></li>
<li>Canon EOS 100D, Canon EOS Rebel SL1, Canon EOS Kiss X7: <em>80000346</em></li>
<li>Canon EOS M2: <em>80000355</em></li>
</ul>
<p>Using a Linux AppImage (read only archive) do the following to be able to install focus pixel maps:</p>
<ul>
<li>extract with --appimage-extract option (it creates a directory called: &quot;squashfs-root&quot;)</li>
<li>copy &quot;ffmpeg&quot; and &quot;raw2mlv&quot; executable in this newly created directory</li>
<li>use ./mlvapp to run application from same directory</li>
<li>now use drag and drop feature to load latest focus pixel maps</li>
</ul>
<h3 id="fix-bad-pixels">Fix Bad Pixels</h3>
<p>Use this option to remove dead pixels from the clip.</p>
<p><img src=":/help/help/badpixels.png" alt="bildschirmfoto 2018-09-23 um 13 40 08"></p>
<h3 id="chroma-smooth">Chroma Smooth</h3>
<p>Smoothes chroma on RAW data.</p>
<h3 id="vertical-stripes">Vertical Stripes</h3>
<p>Some cameras record vertical stripes. Use this option to remove them.</p>
<p><img src=":/help/help/virtstripes.png" alt="bildschirmfoto 2018-09-23 um 13 41 59"></p>
<h3 id="dual-iso">Dual ISO</h3>
<p>Use this &quot;On / Force&quot; to switch Dual ISO processing on. Matching exposures by histogram requires you to select a scene/frame with a wide (ideally full) dynamic range for accurate results. For best results, try using dark-frame subtraction with the same dual ISO and bit depth settings. For faster preview and processing use mean, for better quality use AMaZE interpolation.</p>
<h3 id="pattern-noise">Pattern Noise</h3>
<p>This is the pattern noise reduction algorithm by a1ex.</p>
<h3 id="raw-black-level">RAW Black Level</h3>
<p>Adjust the RAW Black Level if it was not correct in the metadata (mostly it is). If this parameter is wrong, picture shadows get pink or green.</p>
<h3 id="raw-white-level">RAW White Level</h3>
<p>Adjust the RAW White Level if it was not correct in the metadata. If &quot;Highlight Reconstruction&quot; does not work, mostly RAW White Level is set wrong and has to be corrected (lowered).</p>
<h2 id="4-2-cut-in-cut-out">4.2 Cut In &amp; Cut Out</h2>
<p>This range of the clip will be played back and exported only.</p>
<h2 id="4-3-processing">4.3 Processing</h2>
<h3 id="exposure-contrast">Exposure &amp; Contrast</h3>
<p>Correct the exposure in EV and adjust the contrast.</p>
<h3 id="white-balance-temperature-and-tint-">White Balance (Temperature and Tint)</h3>
<p>The white balance can be adjusted manually using the two sliders, or using the picker. When using the picker, use the button in the right of the pipette button, to toggle between &quot;grey&quot; and &quot;skin&quot;. Picking on grey adjusts the white balance on uncolored areas, picking on skin adjusts white balance on human skin.</p>
<h3 id="clarity">Clarity</h3>
<p>The Clarity slider is useful, when it comes to give your images extra punch and impact, or to give it a dreamy look.</p>
<h3 id="saturation">Saturation</h3>
<p>Adjust the saturation intensity of all colors.</p>
<h3 id="vibrance">Vibrance</h3>
<p>Adjust the saturation in dependency, how saturated colors are already.</p>
<h3 id="curve-dark-light-strength-range-">Curve (Dark/Light Strength/Range)</h3>
<p>Adjust &quot;how black black&quot; and &quot;how white white is&quot;.</p>
<h3 id="lighten">Lighten</h3>
<p>Lightens the picture, specially dark parts.</p>
<h3 id="highlight-reconstruction">Highlight Reconstruction</h3>
<p>Remove pink highlights. </p>
<p><em>Note 1: if it does not work, mostly RAW White Level is set wrong.</em></p>
<p><em>Note 2: for dual iso clips, pink highlights can not always be detected.</em></p>
<h3 id="highlights">Highlights</h3>
<p>Analyses and adjusts the highlights using a blurred mask.</p>
<h3 id="shadows">Shadows</h3>
<p>Analyses and adjusts the shadows using a blurred mask.</p>
<h3 id="gradation-curves">Gradation Curves</h3>
<p>Adjust gradation curves independently for Y, R, G, B.</p>
<h2 id="4-4-profile">4.4 Profile</h2>
<h3 id="profile-preset">Profile Preset</h3>
<p>Quick setup for the following parameters.</p>
<h3 id="tonemap-function">Tonemap Function</h3>
<p>After the initial three stages of processing: white balance, gamut conversion and exposure, the data is still linear and unclipped, at this point MLV App applies the selected &quot;tonemapping function&quot;. This could be any function you want, it could be an actual tonemapping function like Reinhard, which rolls off the highlights smoothly but still keeps a &quot;linear&quot; intention, it could be a transfer/gamma function such as those defined by Rec709 or sRGB, or it could even be a LOG transfer function. The tonemapping functions are offered as presets, but you could add anything you want in the source code of MLV App.</p>
<h3 id="processing-gamut">Processing Gamut</h3>
<p>Defines, which colour gamut MLV App will convert camera data to. It is simply choosing an RGB colour space except without a transfer function (sometimes called gamma). Only the primaries. This parameter is disabled, if camera matrix is set to &quot;Don&#39;t Use Camera Matrix&quot;.</p>
<h3 id="gamma">Gamma</h3>
<p>A numerical value defining gamma as a power. Applied to the image after the tonemapping function. If the tonemapping function already did &quot;gamma&quot;, for example the rec709 function, gamma should be 1.0 if you want to stick to rec709 standard strictly. However I would not recommend anyone tries to follow the rec709 standard exactly, it clips really ugly. Much better to select Reinhard as tonemapping function, for smooth highlight rolloff, then approximate the rec709 transfer function on top of that, with a gamma value of 2.0.</p>
<h3 id="allow-creative-adjustment">Allow Creative Adjustment</h3>
<p>Disable this checkbox, to get a correct transformation. Enable this checkbox, to change the look of the footage with curve tools and other parameters.</p>
<h3 id="camera-matrix">Camera Matrix</h3>
<ul>
<li>Don&#39;t Use Camera Matrix: camera&#39;s native RGB channels are interpreted as rec709 primaries, and white balance is done in those colour channels - it is not recommended for accuracy, also different cameras will not match.</li>
<li>Use Camera Matrix: camera colours are converted to MLV App&#39;s processing gamut accurately using camera specific matrix, and white balance is done in LMS colour space (where the R, G and B channels imitate eye colour cells), which should preserve colour constancy better.</li>
<li>Uncolorscience Fix: Same as use camera matrix, except the white balance is not done in LMS gamut, instead it is one that @Danne came up with by tweaking matrix values, it helps reduce blue clipping at lower colour temperatures (2000-3000K), but should not be used if there aren&#39;t any clipping problems, as it can and will affect colour quality or accuracy. This mode will be removed when BetterProcessing branch is complete (it should fix the clipping issues). </li>
</ul>
<h3 id="cyan-highlight-fix">Cyan Highlight Fix</h3>
<p>Use this, if the highlights are clipped and got cyan.</p>
<h2 id="4-5-details">4.5 Details</h2>
<h3 id="chroma-separation">Chroma Separation</h3>
<p>This enables also Chroma Blur Radius. If disabled, &quot;Sharpen&quot; will sharpen all channels. If enabled, &quot;Sharpen&quot; will sharpen luminance channel only.</p>
<h3 id="sharpen">Sharpen</h3>
<p>Sharpen the image. <em>Note: see also Chroma Separation.</em> Use the Masking slider, to apply sharpen on edges only (slider full right).</p>
<h3 id="chroma-blur-radius">Chroma Blur Radius</h3>
<p>Blur the chroma channels using the given pixel radius. This is useful to remove color noise, false color artifacts, ...</p>
<h3 id="denoiser-2d-median-">Denoiser (2D median)</h3>
<p>This is a very simple 2D median denoiser. Window size and Strength can be adjusted.</p>
<h3 id="denoiser-rbf">Denoiser RBF</h3>
<p>This is a denoiser which works via recursive bilateral filtering. MLVApp separates the filter to luma and chroma. The filter radius can be defined.</p>
<h3 id="grain">Grain</h3>
<p>Use the grain strength slider to add some very simple generated film grain. Use the grain luma weight slider to apply more grain to highlights and less grain to shadows.</p>
<h2 id="4-6-hsl-hue-saturation-luminance-">4.6 HSL (Hue Saturation Luminance)</h2>
<h3 id="hue-vs-hue">Hue vs. Hue</h3>
<p>Adjust the color in relation to color. For example: make yellow more green (+) or red (-).</p>
<h3 id="hue-vs-saturation">Hue vs. Saturation</h3>
<p>Adjust saturation in relation to color. For example: make blue -&gt; grey (-), but red -&gt; red (+).</p>
<h3 id="hue-vs-luminance">Hue vs. Luminance</h3>
<p>Adjust luminance in relation to color. For example: make blue darker (-), but red brighter (+).</p>
<h3 id="luminance-vs-saturation">Luminance vs. Saturation</h3>
<p>Adjust saturation in relation to luminance. For example: desaturate shadows (- on the left).</p>
<h2 id="4-7-toning">4.7 Toning</h2>
<p>Select a hue and a strength. This simulates a hardware color filter.</p>
<h2 id="4-8-linear-gradient">4.8 Linear Gradient</h2>
<p>This set of parameters offers a kind of graduated ND filter. Additionally to exposure, contrast can be adjusted as well. </p>
<p>The position and length of the filter can be drawn on the picture using the pen button. Hovering on the lines on the picture, marks the lines yellow. Clicking an the marked lines makes it possible to adjust the position of the filter.</p>
<p><img src=":/help/help/gradient.png" alt="bildschirmfoto 2018-08-29 um 12 45 19"></p>
<p>Hide the lines by collapsing the &quot;Linear Gradient&quot; group box.</p>
<h2 id="4-9-lut">4.9 LUT</h2>
<p>Enable and select a 1D/3D .cube LookUpTable. </p>
<h2 id="4-10-filter">4.10 Filter</h2>
<p>Enable, select, and adjust Strength of a predefined picture look.</p>
<h2 id="4-11-lens-correction">4.11 Lens Correction</h2>
<h3 id="vignette">Vignette</h3>
<p>Use strength slider to correct existing vignettes in your footage (-&gt; positive strength) or as vignette effect (-&gt;negative strength). The radius slider defines the area starting from the middle, which rests untouched. The shape slider can be used to change the shape of the vignette between circle and oval.</p>
<h3 id="ca-correction-red-blue">CA Correction Red / Blue</h3>
<p>These two sliders shift the RAW channels with the goal to correct CAs. </p>
<h3 id="ca-desaturate-radius">CA Desaturate / Radius</h3>
<p>The CA threshold slider should be setup to the most possible left value where CAs disappear. This should happen mostly between 85..95, but might be different from clip to clip. Radius slider can be used for large CAs. Here values between 1..5 are mostly best. This feature works on debayered RGB data.</p>
<h2 id="4-12-transformation">4.12 Transformation</h2>
<h3 id="width-stretch">Width Stretch</h3>
<p>When using anamorph lenses, the stretch factor can be adjusted here.</p>
<h3 id="height-stretch">Height Stretch</h3>
<p>Wrong height ratio can be corrected here, when using pixel binning and skipping.
<em>Note: if metadata exists, MLV App adjusts this parameter automatically.</em></p>
<h3 id="final-resolution">Final resolution</h3>
<p>A grey label shows the resulting final resolution of your clip.</p>
<h3 id="upside-down">Upside Down</h3>
<p>This option turns the picture by 180Â°.</p>
<h3 id="ffmpeg-vid-stab">ffmpeg vid.stab</h3>
<p>Vid.stab can be used to stabilize shaky footage. Therefor the export codec must be H.264! The function of the parameters is described on ffmpeg and vid.stab pages.</p>
<h1 id="5-processing-pipeline">5. Processing pipeline</h1>
<p>Almost everything in processing is done through 65535-long lookup tables for more speed than using actual calculations (and quite badly organized in my opinion, all the arrays[65536] in the processing object are look up tables.</p>
<p>This use of 16 bit integers only causes a huge amount of difficulties with not clipping things, and is why developing new features like highlights and shadows got difficult (also why I did it wrong - did not want to clip stuff - more on this later). However all the processing features I created never ever clipped anything [1], so it&#39;s the same result as if it was done in floats... just more difficult to program new features.</p>
<ol>
<li>well, almost - information could still be lost if no tonemapping enabled, exposure increased followed by saturation reduction. There are probably a few other minor ways to lose some information.</li>
</ol>
<p>The intention of these methods was to make it run quick, and I remember at the very start (back in early 2017), I could get one frame processed in 40ms on one thread. Not sure if it was ever that fast by the time it got a GUI.</p>
<h2 id="processing-a-frame">Processing a frame</h2>
<p>When changing the parameters exposure, temperature, dark/light strength/range, lighten and profile, in background some matrices were created and precalculated. So rendering the frame can be faster, because only the matrices have to be applied.</p>
<h4 id="start-of-processing">start of processing</h4>
<p><code>applyProcessingObject()</code></p>
<ol>
<li>shadows and highlights... (just remembered there is actually a big problem in the implementation)
Done on debayered raw image before black/white level correction and exposure (this is the problem)</li>
</ol>
<p><code>applyProcessingObject()</code> calls <code>apply_processing_object()</code> split in to threads</p>
<ol>
<li>Black and white level correction (look up table)</li>
<li>Matrix (does white balance, no camera matrix stuff) - there are some variables to realize contrast and clarity. This work exactly like highlights/shadows but:</li>
<li>contrast: combines shadows(-)/highlights(+) with no blurred picture</li>
<li>clarity: combines contrast(+) and shadows(+)/highlights(-)</li>
<li>Gamma through lookup table, gamma look up table also has exposure and tonemap function applied in it all in one go (so highlight data won&#39;t get clipped before tonemapping)</li>
<li>Highlight reconstruction done same time as the matrix. That works by reconstructing the green channel at the point where it was clipped.
For dual iso clips, the information of highest_green (input for reconstruction) gets lost on dual iso stitching, and is different in each frame. In the end it seems like there is a gaussian curve around a peak (which may be there, may be not, sometimes it is small, sometimes it is high). That is why an algorithm was implemented, which trys to find this peak, if there is one.
Starting from full 16bit (65535) and searching all local maxima, a maxima which is bigger than a limit is searched. If the maxima become bigger than a smaller limit, green signal was found (no peak found -&gt; no clipped green). This algorithm has to run for each frame...</li>
<li>For the linear gradient a second layer is calculated, using a modified copy of the matrices. Only the visible part is calculated, for speed reasons. Using a mask the gradient layer is applied on the main picture.</li>
<li>Saturation using some weird algorithm Ilia came up with that seemed quick, also using strange lookup tables. Vibrance works exactly like saturation, but calculates RGB to (H)S(V) (S channel only) to be able to set saturation in dependency to saturation already being there. The less saturation there was before, the more saturation will be after applying vibrance.</li>
<li>Toning</li>
<li>Contrast look up table</li>
<li>LUT applied</li>
<li>neural network filter applied</li>
</ol>
<p><code>apply_processing_object()</code> returns to <code>applyProcessingObject()</code>. Following tasks done with openMP</p>
<ol>
<li>Denoise</li>
<li>if enabled, conversion to ycbcr through some lookup tables</li>
<li>Sharpening, on all channels if rgb, or on just Y channel if ycbcr</li>
<li>if chroma blur enabled and in ycbcr, cb and cr channels are blurred</li>
<li>convert back to rgb from ycbcr</li>
<li>Grain</li>
</ol>
